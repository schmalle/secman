# Implementation Plan: CSV-Based User Mapping Upload

**Branch**: `016-i-want-to` | **Date**: 2025-10-13 | **Spec**: [spec.md](spec.md)
**Input**: Feature specification from `/specs/016-i-want-to/spec.md`

**Note**: This plan is generated by the `/speckit.plan` command. See `.specify/templates/commands/plan.md` for the execution workflow.

## Summary

This feature extends the existing Excel-based user mapping upload (Feature 013) to support CSV format. Administrators will be able to upload CSV files exported directly from AWS Organizations containing `account_id` and `owner_email` columns. The system will extract these fields, assign domain value "-NONE-" (or use optional domain column if present), and create UserMapping records using the same validation and duplicate detection logic as the existing Excel upload. The CSV upload button will be added next to the Excel upload button on the `/admin/user-mappings` page, providing administrators with format flexibility while maintaining consistent behavior and security.

**Key Technical Approach**:
- Extend existing ImportController to add CSV upload endpoint
- Create CSVUserMappingParser service mirroring ExcelUserMappingParser
- Reuse UserMappingRepository and validation logic from Feature 013
- Handle scientific notation in account IDs (Excel export format)
- Add CSV template download endpoint
- Update frontend UserMappingUpload component with CSV button

## Technical Context

**Language/Version**: Kotlin 2.1.0 / Java 21 (backend), TypeScript/JavaScript (frontend - Astro 5.14 + React 19)
**Primary Dependencies**:
- Backend: Micronaut 4.4, Hibernate JPA, Apache Commons CSV (or similar for CSV parsing)
- Frontend: Astro, React 19, Axios
**Storage**: MariaDB 11.4 (existing UserMapping entity from Feature 013, no schema changes)
**Testing**:
- Backend: JUnit 5 + MockK (contract tests, integration tests, unit tests)
- Frontend: Playwright (E2E tests)
**Target Platform**: Web application (Docker containerized, multi-arch AMD64/ARM64)
**Project Type**: web - existing Micronaut backend + Astro/React frontend
**Performance Goals**:
- 1000-row CSV file processes in <10 seconds
- Same performance characteristics as Excel upload
**Constraints**:
- 10MB maximum file size (consistent with Excel upload)
- CSV parsing must handle UTF-8 and ISO-8859-1 encodings
- Scientific notation parsing for AWS account IDs
- Case-insensitive column header matching
**Scale/Scope**:
- Single new endpoint (POST /api/import/upload-user-mappings-csv)
- One new service class (CSVUserMappingParser)
- Frontend: Update 1 existing component (UserMappingUpload.tsx or equivalent)
- Estimated 400-600 lines backend + 100-150 lines frontend
- 50-80 test cases (contract + integration + E2E)

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

### I. Security-First ✅ PASS

- **File upload validation**: CSV file size (10MB), extension (.csv), content-type checks REQUIRED
- **Input sanitization**: Email format validation, AWS account ID format (12 digits), domain validation (or "-NONE-" assignment)
- **RBAC enforcement**: @Secured("ADMIN") on CSV upload endpoint, role check in frontend
- **Sensitive data**: No PII logged; error messages sanitized
- **Token storage**: Existing JWT in sessionStorage (no changes)

**Compliance**: All security requirements from spec align with Security-First principle.

### II. Test-Driven Development (NON-NEGOTIABLE) ✅ PASS

- **Contract tests first**: CSV upload endpoint contract test written before implementation
- **Integration tests**: CSV parsing service tests written first
- **Unit tests**: Validation logic, duplicate detection tests written first
- **Red-Green-Refactor**: Tests MUST fail before implementation
- **Coverage target**: ≥80% for new code
- **Testing tools**: JUnit 5 + MockK (backend), Playwright (frontend E2E)

**Compliance**: Spec includes detailed acceptance scenarios. Plan will generate contract tests first.

### III. API-First ✅ PASS

- **RESTful design**: POST /api/import/upload-user-mappings-csv follows existing pattern
- **Consistent response**: Uses same ImportResult format as Excel upload
- **HTTP status codes**: 200 (success), 400 (validation error), 401 (unauthorized), 403 (forbidden), 413 (file too large)
- **Backward compatibility**: No breaking changes to existing endpoints
- **Error format**: Consistent with Feature 013 Excel upload

**Compliance**: Extends existing API patterns without breaking changes.

### IV. Docker-First ✅ PASS

- **Containerization**: No changes to Docker setup (backend + frontend already containerized)
- **Multi-arch**: Existing AMD64/ARM64 support maintained
- **Environment config**: No new environment variables required
- **docker-compose.yml**: No changes needed
- **Dependencies**: Apache Commons CSV (or equivalent) added to backend build.gradle.kts

**Compliance**: Builds on existing Docker infrastructure.

### V. Role-Based Access Control (RBAC) ✅ PASS

- **@Secured annotation**: CSV upload endpoint annotated with @Secured("ADMIN")
- **Frontend role check**: UI button visibility gated by ADMIN role
- **Service layer**: Validation and persistence respect same access control as Excel upload
- **Workgroup filtering**: Not applicable (UserMapping is ADMIN-only, no workgroup filtering)

**Compliance**: Consistent RBAC enforcement across all layers.

### VI. Schema Evolution ✅ PASS

- **No schema changes**: Uses existing UserMapping entity from Feature 013
- **Entity annotations**: No modifications to @Entity, @Table, @Index, or constraints
- **Migration**: No database migration required
- **Data model**: domain field populated with "-NONE-" for CSV uploads (new convention, not schema change)

**Compliance**: Zero schema impact; purely additive feature.

**Overall Gate Result**: ✅ **PASSED** - All constitutional principles satisfied. Feature is a clean extension of existing functionality with no governance violations.

## Project Structure

### Documentation (this feature)

```
specs/016-i-want-to/
├── spec.md              # Feature specification (completed)
├── plan.md              # This file (/speckit.plan command output)
├── research.md          # Phase 0 output (/speckit.plan command)
├── data-model.md        # Phase 1 output (/speckit.plan command)
├── quickstart.md        # Phase 1 output (/speckit.plan command)
├── contracts/           # Phase 1 output (/speckit.plan command)
│   └── csv-upload.yaml  # OpenAPI contract for CSV upload endpoint
├── tasks.md             # Phase 2 output (/speckit.tasks command - NOT created by /speckit.plan)
└── checklists/
    └── requirements.md  # Spec quality checklist (completed)
```

### Source Code (repository root)

```
src/backendng/
├── src/main/kotlin/com/secman/
│   ├── controller/
│   │   └── ImportController.kt        # EXTEND: Add uploadUserMappingsCSV() method
│   ├── service/
│   │   └── CSVUserMappingParser.kt    # NEW: CSV parsing service
│   ├── repository/
│   │   └── UserMappingRepository.kt   # EXISTING: No changes (reuse)
│   └── domain/
│       └── UserMapping.kt             # EXISTING: No changes (reuse)
├── src/main/resources/
│   └── templates/
│       └── user-mapping-template.csv  # NEW: CSV template file
└── src/test/kotlin/com/secman/
    ├── contract/
    │   └── CSVUploadContractTest.kt   # NEW: Contract tests for CSV endpoint
    └── service/
        └── CSVUserMappingParserTest.kt # NEW: Unit tests for CSV parser

src/frontend/
├── src/pages/admin/
│   └── user-mappings.astro            # EXTEND: Add CSV upload button
├── src/components/
│   └── UserMappingUpload.tsx          # EXTEND: Add CSV upload handler (if separate component)
└── tests/e2e/
    └── csv-upload.spec.ts             # NEW: E2E tests for CSV upload

build.gradle.kts                        # MODIFY: Add Apache Commons CSV dependency
```

**Structure Decision**: Web application structure (Option 2) is already established. This feature extends existing backend controller and frontend components without introducing new modules. All new files follow the existing package/directory conventions from Feature 013 (Excel upload).

**Rationale**: CSV upload is a direct parallel to Excel upload, so we mirror the implementation structure:
- Same controller (ImportController) with parallel endpoint
- Parallel service (CSVUserMappingParser vs ExcelUserMappingParser)
- Shared repository and entity (UserMappingRepository, UserMapping)
- Frontend: Extend same admin page with additional upload button

## Complexity Tracking

*No constitutional violations - this section intentionally empty.*

**Justification**: Feature adds CSV support alongside existing Excel upload with no deviations from constitutional principles. All gates passed without exceptions or simplifications.

---

## Phase 0: Research & Technology Decisions

**Status**: Ready to execute

### Research Tasks

Based on Technical Context unknowns, the following research tasks will be executed:

1. **CSV Parsing Library Selection**
   - **Question**: Which CSV parsing library best fits Micronaut + Kotlin for parsing RFC 4180 CSV with encoding detection?
   - **Options**: Apache Commons CSV, OpenCSV, Kotlin CSV, kotlinx.serialization
   - **Criteria**: Performance, UTF-8/ISO-8859-1 support, delimiter auto-detection, scientific notation handling

2. **Scientific Notation Parsing**
   - **Question**: How to reliably parse AWS account IDs in scientific notation (e.g., 9.98987E+11) to 12-digit strings?
   - **Options**: BigDecimal parsing, String manipulation, custom parser
   - **Criteria**: Accuracy (no precision loss), robustness (handle edge cases like 1.0E+12)

3. **CSV Encoding Detection**
   - **Question**: Best approach to detect CSV encoding (UTF-8 vs ISO-8859-1) automatically?
   - **Options**: Apache Tika, juniversalchardet, manual BOM detection
   - **Criteria**: Accuracy, performance impact, dependency weight

4. **Delimiter Detection**
   - **Question**: How to auto-detect CSV delimiter (comma, semicolon, tab)?
   - **Options**: Apache Commons CSV auto-detection, manual first-line analysis, configuration-based
   - **Criteria**: Reliability, edge case handling (quoted delimiters)

5. **Frontend File Input Pattern**
   - **Question**: Best practice for adding second file upload button (CSV) next to existing Excel upload in React/Astro?
   - **Options**: Separate buttons with shared handler, unified button with format dropdown, separate components
   - **Criteria**: UX clarity, code reuse, maintainability

### Research Execution

Research will be consolidated in `research.md` with format:
- **Decision**: [Chosen approach]
- **Rationale**: [Why chosen based on criteria]
- **Alternatives Considered**: [What else was evaluated]
- **Implementation Notes**: [Key integration points]

---

## Phase 1: Design & Contracts

**Status**: Pending Phase 0 completion

### Deliverables

1. **data-model.md**:
   - Reuse existing UserMapping entity (no changes)
   - Document domain field convention: "-NONE-" for CSV uploads without domain column
   - CSV parsing data flow (file → rows → validation → UserMapping entities)

2. **contracts/csv-upload.yaml**:
   - OpenAPI spec for POST /api/import/upload-user-mappings-csv
   - Multipart/form-data request (csvFile: binary)
   - Response: ImportResult { message, imported, skipped, errors }
   - Error responses: 400, 401, 403, 413, 500

3. **quickstart.md**:
   - How to upload CSV user mappings (admin workflow)
   - CSV format requirements (columns, encoding, size)
   - Troubleshooting common errors (invalid format, missing columns, duplicate mappings)

4. **Agent Context Update**:
   - Run `.specify/scripts/bash/update-agent-context.sh claude`
   - Add CSV upload endpoint to CLAUDE.md API Endpoints section
   - Add CSVUserMappingParser to File Locations
   - Preserve manual additions between markers

---

## Phase 2: Task Generation

**Status**: Not started (requires `/speckit.tasks` command after Phase 1)

**Note**: Task generation happens in a separate command (`/speckit.tasks`) after design artifacts are reviewed and approved.

---

## Next Steps

1. Execute Phase 0: Generate `research.md` by dispatching research agents for each unknown
2. Review research findings and update Technical Context if needed
3. Execute Phase 1: Generate `data-model.md`, `contracts/`, and `quickstart.md`
4. Update agent context (CLAUDE.md) with new endpoint and parser
5. Re-run Constitution Check (expected: still passing)
6. Report completion with artifact paths
7. Wait for user to run `/speckit.tasks` for task breakdown

---

**Plan Generation Date**: 2025-10-13
**Constitution Version**: 1.0.0
**Ready for Phase 0 Execution**: ✅ YES
